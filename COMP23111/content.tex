% Set the author and title of the compiled pdf
\hypersetup{
  pdftitle = {\Title},
  pdfauthor = {\Author}
}

\section{An introduction to Database Management Systems}

DataBase Management Systems (DBMS's) are a type of middleware that provide a
layer of abstraction for dealing with databases. It is nearly always unnecessary
to write software from scratch that interfaces with a database, since a lot of
database operations will share a significant amount of logic.

Henceforth, a lot of the functionality required of applications that make use of
a database is placed into a DBMS, which application developers can make use and
save time. The DBMS acts as a service, that is well implemented and is able to
enforce good practices and advanced techniques such as concurrency, sharding,
recovery management and transactions.

Some advantages of using a DBMS include:

\begin{itemize}
  \item It decouples data inside a database from the application using it.
        Either can be re-written at any time so long as they still provide/use
        the same interface.
  \item Since the data is decoupled from the application, using a DBMS (in
        theory) lowers the development cost of the application.
  \item Most DBMS are scalable, concurrent, fault tolerant, authorisation
        control (often role based for organisations).
\end{itemize}

Even though the DBMS aims to provide a layer of abstraction for a user
application, there are several layers of abstraction within the DBMS itself.
These are:

\begin{tabularx}{\textwidth}{>{\bfseries}l X}
  Physical & Deals with the file(s) that is written to the
             storage medium that will hold the database. Needs to know about
             file formats, indexing, compression, etc.\\
  Logical  & Mainly concerned with mapping the raw data into database
             `concepts' such as tables, views etc. It is here that the formal
             specification of the database is defined, commonly used models
             include \textit{relational, XML based and document based}\\
  View     & Ensures that only authorised people can view the data.\\
\end{tabularx}

If the database is using a relational format, then it will be defined by a
schema. A schema dictates how the database is formatted; what tables there are,
and what datatypes their columns take. An instance of a database is the content
(data) inside of the database at a particular point in time. There is a certain
isomorphism between relational databases and imperative programming languages; a
schema would be akin to the declaration of variables (i.e. their names and
types), while the instance would be their values at a particular point in the
program's execution.

Irrespective of what logical model a database uses, most DBMS use between one
and three languages to interface with a user/application. These are:

\begin{itemize}
  \item Data Definition Language - used for specifying schema.
  \item Data Manipulation Language - used for mutating the data in the database.
  \item Data Query Language - used to access data in the database.
\end{itemize}

Often DBMS languages will be both a DML and a DQL, and sometimes a DDL too! One
such example is SQL, does all of the above!

\section{Relational Algebra and SQL}

Relational algebra is designed for modelling data stored in relational databases
(i.e. tables) and defining queries on it. It can perform unary operations (such
as growing, shrinking and selecting from tables), or binary operations (union,
intersection, difference, product, join).

\subsection{Selection $\sigma$}

The $\sigma$ operator can select rows that meet a certain criteria from the
table.

\begin{center}
  \begin{tabular}{lll}
    \multicolumn{3}{c}{\textbf{Alcohol-Selection}}\\
    {Type} & {Strength} & {Colour}\\ \hline
    Wine          & 11                & Red\\
    Beer          & 4.2               & Yellow\\
    Wine          & 12.8              & White\\
    Port          & 18                & Carmine\\
    Ale           & 11                & Red\\
  \end{tabular}
\end{center}

If we run $\text{\it Fine-Wines}:=\sigma_{Type=Wine}(\text{\it Alcohol-
Selection})$, we'll end up with:

\begin{center}
  \begin{tabular}{lll}
    \multicolumn{3}{c}{\textbf{Fine-Wines}}\\
    {Type} & {Strength} & {Colour}\\ \hline
    Wine          & 11                & Red\\
    Wine          & 12.8              & White\\
  \end{tabular}
\end{center}

\subsection{Projection $\pi$}

The $\pi$ operator can select rows instead of columns. If we do $\text{\it
Anonymous-Drinks} := \pi_{Strength, Colour}(\text{\it Alcohol-Selection})$:

\begin{center}
  \begin{tabular}{ll}
    \multicolumn{2}{c}{\textbf{Anonymous-Drinks}}\\
    {Strength} & {Colour}\\ \hline
    11         & Red\\
    4.2        & Yellow\\
    12.8       & White\\
    18         & Carmine\\
  \end{tabular}
\end{center}

Notice that both the 11\% Ale and the 11\% Red Wine have the same strength and
colour values. Consequently, the projection operator combines those rows into
one so the same result isn't displayed twice.

Projection can also be used to do simple arithmetic, $\text{\it Test} :=
\pi_{Strength + Strength->DStrength, Colour}(\text{\it Anonymous-Drinks})$:

\begin{center}
  \begin{tabular}{ll}
    \multicolumn{2}{c}{\textbf{Test}}\\
    {DStrength} & {Colour}\\ \hline
    22         & Red\\
    8.4        & Yellow\\
    25.6       & White\\
    36         & Carmine\\
  \end{tabular}
\end{center}

\subsection{Product $\times$}

\begin{center}
  \begin{tabular}{lll}
    \multicolumn{3}{c}{\textbf{Shops}}\\
    {Name}           & {Dodginess} & {Price}\\ \hline
    Ali's            & High        & Medium \\
    Tesco            & Low         & Medium \\
    New Zeland Wines & X.High      & Low    \\
  \end{tabular}
\end{center}

We could do a cross product with the Shops and the Alcohol-Selection tables
$\text{\it Grog-Shops} := \text{\it Shops} \times \text{\it Alcohol-Selection}$:

\begin{center}
  \begin{tabular}{llllll}
    \multicolumn{6}{c}{\textbf{Grog-Shops}}\\
    {Name}           & {Dodginess} & {Price} & {Type} & {Strength} & {Colour}\\ \hline
    Ali's            & High        & Medium  & Wine          & 11                & Red\\
    Ali's            & High        & Medium  & Beer          & 4.2               & Yellow\\
    Ali's            & High        & Medium  & Wine          & 12.8              & White\\
    Ali's            & High        & Medium  & Port          & 18                & Carmine\\
    Ali's            & High        & Medium  & Ale           & 11                & Red\\
    Tesco            & Low         & Medium  & Wine          & 11                & Red\\
    Tesco            & Low         & Medium  & Beer          & 4.2               & Yellow\\
    Tesco            & Low         & Medium  & Wine          & 12.8              & White\\
    Tesco            & Low         & Medium  & Port          & 18                & Carmine\\
    Tesco            & Low         & Medium  & Ale           & 11                & Red\\ 
    New Zeland Wines & X.High      & Low     & Wine          & 11                & Red\\
    New Zeland Wines & X.High      & Low     & Beer          & 4.2               & Yellow\\
    New Zeland Wines & X.High      & Low     & Wine          & 12.8              & White\\
    New Zeland Wines & X.High      & Low     & Port          & 18                & Carmine\\
    New Zeland Wines & X.High      & Low     & Ale           & 11                & Red\\
  \end{tabular}
\end{center}

\subsection{Renaming $\rho$}

The notation for renaming columns is pretty simple; $\text{\it Drinks} :=
\rho_{Name, Strength, Hue}(\text{\it Alcohol-Selection})$

\begin{center}
  \begin{tabular}{lll}
    \multicolumn{3}{c}{\textbf{Drinks}}\\
    {Name} & {Strength} & {Hue}\\ \hline
    Wine          & 11                & Red\\
    Beer          & 4.2               & Yellow\\
    Wine          & 12.8              & White\\
    Port          & 18                & Carmine\\
    Ale           & 11                & Red\\
  \end{tabular}
\end{center}

\subsection{Join $\Join$}

If we had:

\begin{center}
  \begin{tabular}{lll}
    \multicolumn{2}{c}{\textbf{People}}\\
    {Name} & {Drinks}\\ \hline
    Alice  & Wine\\ 
    Bob    & Beer\\ 
  \end{tabular}
\end{center}

We could join it with the Grog-Shops table, using $\text{\it Fave-Shops} :=
People \Join_{People.Drinks=Grog-Shops.Type}(\text{\it Grog-Shops})$

\begin{center}
  \begin{tabular}{lllllll}
    \multicolumn{7}{c}{\textbf{Fave-Shops}}\\
    {Person.Name} & {Grog-Shops.Name}& {Dodginess} & {Price} & {Type} & {Strength} & {Colour}\\ \hline
    Alice         &  Ali's            & High        & Medium  & Wine          & 11                & Red\\
    Bob           &  Ali's            & High        & Medium  & Beer          & 4.2               & Yellow\\
    Alice         &  Ali's            & High        & Medium  & Wine          & 12.8              & White\\
    Alice         &  Tesco            & Low         & Medium  & Wine          & 11                & Red\\
    Bob           &  Tesco            & Low         & Medium  & Beer          & 4.2               & Yellow\\
    Alice         &  Tesco            & Low         & Medium  & Wine          & 12.8              & White\\
    Alice         &  New Zeland Wines & X.High      & Low     & Wine          & 11                & Red\\
    Bob           &  New Zeland Wines & X.High      & Low     & Beer          & 4.2               & Yellow\\
    Alice         &  New Zeland Wines & X.High      & Low     & Wine          & 12.8              & White\\
  \end{tabular}
\end{center}

If two tables have a column of the same name, then they can be joined naturally
without specifying which columns to join explicitly.

\subsection{Distinct $\delta$}

The $\delta$ operator will ensure that no rows are duplicated.

\subsection{Chaining operators}

Just like in normal algebra, you can chain operators:

$\delta(\pi_{Strength, Colour}(\text{\it Alcohol-Selection}))$

Gives:

\begin{center}
  \begin{tabular}{lll}
    {Strength} & {Colour}\\ \hline
    11                & Red\\
    4.2               & Yellow\\
    12.8              & White\\
    18                & Carmine\\
  \end{tabular}
\end{center}

\section{SQL Syntax}

\begin{mymulticols}

  \subsection{Selecting rows}

  The SQL command to select rows from a table is:

  \begin{alltt}
  	SELECT <column-name>\\
  	FROM <table-name>;
  \end{alltt}

  If you only want distinct values from a column, use \texttt{DISTINCT}:

  \begin{alltt}
  	SELECT DISTINCT <column-name>\\
  	FROM <table-name>;
  \end{alltt}

  If you want all of the columns, use \texttt{*}:

  \begin{alltt}
  	SELECT *\\
  	FROM <table-name>;
  \end{alltt}

  You can also do derivations:

  \begin{alltt}
  	SELECT salary/2\\
  	FROM <table-name>;
  \end{alltt}

  In order to specify which rows you want from the table, or you want to join two
  tables together, use the \texttt{WHERE} clause:

  \begin{alltt}
  	SELECT *\\
  	WHERE <condition>\\
  	FROM <table-name>;
  \end{alltt}

  \begin{alltt}
  	SELECT *\\
  	WHERE table1.columnx = table2.columny\\
  	FROM table1, table2;
  \end{alltt}

  Use \texttt{AND} to chain multiple conditions in a \texttt{WHERE} clause:

  \begin{alltt}
  	SELECT *\\
  	WHERE x > 100\\
  	AND table1.x = table2.y\\
  	FROM <table-name>;
  \end{alltt}

  \subsubsection{Where conditions}

  You can use the standard $=, <, >$ signs for comparisons between columns,
  but SQL also lets you use \texttt{LIKE}, \texttt{BETWEEN} and \texttt{IS NULL}:

  \begin{alltt}
  	SELECT *\\
  	FROM <table-name>\\
  	WHERE name LIKE '%BOB%';
  \end{alltt}

  \begin{alltt}
  	SELECT *\\
  	FROM <table-name>\\
  	WHERE salary BETWEEN 10000 AND 12000;
  \end{alltt}

  \begin{alltt}
  	SELECT *\\
  	FROM <table-name>\\
  	WHERE previous-convictions IS NULL;
  \end{alltt}

  You can also compare tuples:

  \begin{alltt}
  	SELECT *\\
  	FROM t1, t2\\
  	WHERE (t1.parent, t1.age) = ('Janet', t2.age);
  \end{alltt}

  \subsection{Set operations}

  The three main set operations are \texttt{UNION, EXCEPT} and \texttt{INTERSECT},
  their meaning is rather self evident given their names. An example usage may be:

  \begin{alltt}
  	(SELECT *\\
  	 FROM <table-name>)\\
  	UNION ALL\\
  	(SELECT *\\
  	 FROM <table-name>);
  \end{alltt}

  \subsection{Joins}

  We've already looked at the most common join:

  \begin{alltt}
  	SELECT *\\
  	WHERE table1.columnx = table2.columny\\
  	FROM table1, table2;
  \end{alltt}

  But you can also do it manually:

  \begin{alltt}
  	SELECT *\\
  	FROM table1 JOIN table2\\
  	USING (<column-name>);
  \end{alltt}

  Or with a \texttt{NATURAL JOIN}, which is automatic, but can only be applied
  when columns have identical names:

  \begin{alltt}
  	SELECT *\\
  	FROM table1 NATURAL JOIN table2
  \end{alltt}

  \subsection{Renaming columns}

  You can use the \texttt{FROM} clause to rename tables:

  \begin{alltt}
  	SELECT *\\
  	FROM table1 as a, table2 as b\\
  	where a.col > b.col;
  \end{alltt}

  \subsection{Ordering and other operations}

  \texttt{GROUP BY} can be used to sort rows by a column value:

  \begin{alltt}
  	SELECT *\\
  	FROM <table-name>\\
  	GROUP BY height;
  \end{alltt}

  Other operators such as \texttt{AVG} and \texttt{COUNT} can also be used:

  \begin{alltt}
  	SELECT AVG(salary)\\
  	FROM <table-name>;	
  \end{alltt}

  \begin{alltt}
  	SELECT COUNT(DISTINCT salary)\\
  	FROM <table-name>;	
  \end{alltt}

  \begin{alltt}
    SELECT COUNT(*)\\
    FROM <table-name>;
  \end{alltt}

  \begin{alltt}
    SELECT dept-name, AVG(salary)\\
    FROM staff\\
    GROUP BY dept-name\\
    HAVING AVG(salary) > 30000;
  \end{alltt}

\end{mymulticols}

\section{Designing databases}

Entity-Relationship (ER) Modelling is a simple, high-level conceptual modelling
approach that focuses on data requirements rather than business logic. A
conceptual model is what we aim to produce in the design phase of database
development. It describes the format of the database, they types of entity that
are used, the relationships between entities and constraints on the data.

We can translate a conceptual model into a logical schema, which is often just a
language such as SQL. We can use the logical schema directly to create and
manipulate our database.

\subsection{Entity Relationship Modelling}

There are three basic constructs in ER modelling; entity types, attribute types
and relationship types.

Attribute types consist of the following:

\begin{description}
  \item Simple or Composite\\
    A simple type is atomic, whereas a composite type is made of an amalgamation
    of multiple other types.
  \item Single or Multi valued\\
    Types can either have single values (such as an integer), or they can have a
    value from discrete set of allowed values (multi-valued).
  \item Stored or Derived\\
    Stored attributes are ones where the value of the attribute is directly
    stored by the database (e.g. licence start date), while Derived attributes
    are computed from the values of other attributes (e.g. licence end date =
    start date + 1 year).
  \item Null valued\\
    Can be null.
  \item Complex-valued\\
    Made of arbitrarily nested composite or multivalued attributes.
\end{description}

\marginpar{Remember, ER models don't have primary or foreign keys, they only
have plain keys. Relationships are modelled explicitly in ER rather than
implicitly using keys.}

Keys are important in ER modelling. Entities with a key are bound by uniqueness
constraints; each key must be unique within the entity. There can be more than
one key in an entity type, but there can also be no key, and if this is the
case, then the entity is said to be \textbf{weak}.

\textbf{Carnality ratio} constraints specify the ratio of one entity to
another in a relationship. It can be $1:1, 1:n, n:1, n:m$.

\textbf{Participation constraints} specify if an entity depends on another
entity. If a participation is \textbf{total}, then every entity in the total
entity must participate in some relationship, if the participation is
\textbf{partial}, then some entities may not participate in any relationship.
For example, student:program is total:partial.

\textbf{Weak entities} can only be properly identified if they are related to
some other entity type, an \textbf{owner}. An \textbf{identifying relationship}
is one where a weak entity has a total participation constraint with it's owner.

When we're writing a requirements specification, \textbf{bold} words are entity
types (e.g. \textbf{employees, departments and projects}), \textit{italic} words
are attribute types (e.g. \textit{name, location, phone number}), and
\underline{underlined} words are relationship types (e.g. employees
\underline{belong to a} department).

\subsubsection{ER Notation}

\begin{mymulticols}

  \begin{description}
    \item \textbf{Entity type}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[entity] {Employee};
      \end{tikzpicture}
    \end{center}

    \item \textbf{Weak entity type}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[weak entity] {Dependent};
      \end{tikzpicture}
    \end{center}

    \item \textbf{Attribute}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[entity] (emp) {Employee};
        \node[attribute] [above=1cm of emp] {Name} edge (emp);
      \end{tikzpicture}
    \end{center}

    \item \textbf{Weak attribute}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[weak entity] (emp) {Dependent};
        \node[attribute] [above=1cm of emp] {\discriminator{Name}} edge (emp);
      \end{tikzpicture}
    \end{center}

    \item \textbf{Derived attribute}\\
    \begin{center}
      \begin{tikzpicture}[node distance=1.5cm, every edge/.style={link}]
        \node[entity] (emp) {Employee};
        \node[attribute] [above=1cm of emp] {Date of Birth} edge (emp);
        \node[derived attribute] [left= 1cm of emp] {Age} edge (emp);
      \end{tikzpicture}
    \end{center}

    \item \textbf{Multivalue}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[entity] (emp) {Employee};
        \node[multi attribute] [above=1cm of emp] {Children} edge (emp);
      \end{tikzpicture}
    \end{center}

    \item \textbf{Key}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[entity] (emp) {Employee};
        \node[attribute] [above=1cm of emp] {\key{ID}} edge (emp);
      \end{tikzpicture}
    \end{center}

    \item \textbf{Relationship (plus carnality ratio)}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[entity] (emp) {Employee};
        \node[relationship] [above=1cm of emp] (rel) {Works for};
        \node[entity] [above=1cm of rel] (dep) {Department};
        \draw[link] (rel.90) |- node [below, auto] {1} (dep.270);
        \draw[link] (rel.270) |- node [above, auto] {N} (emp.90);
      \end{tikzpicture}
    \end{center}

    \item \textbf{Identifying relationship}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[entity] (emp) {Employee};
        \node[ident relationship] [above=1cm of emp] (rel) {Dependent of} edge (emp);
        \node[weak entity] [above=1cm of rel] (dep) {Dependent} edge (rel);
      \end{tikzpicture}
    \end{center}

    \item \textbf{Recursive relationship}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[entity] (emp) {Employee};
        \node[relationship] [below=1cm of emp] (rel) {Dependent of};
        \draw[link] (rel.180) |- node [left, auto] {Supervisor} (emp.180);
        \draw[link] (emp) -| node [left, auto] {Supervisee} (rel.360);
      \end{tikzpicture}
    \end{center}

    \item \textbf{Participation constraint}\\
    \begin{center}
      \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
        \node[entity] (emp) {Project};
        \node[relationship] [above=1cm of emp] (rel) {Controls} edge [total] (emp);
        \node[entity] [above=1cm of rel] (dep) {Department} edge (rel);
      \end{tikzpicture}
    \end{center}
  \end{description}
\end{mymulticols}

\subsubsection{Specialising entities}

It's often efficient to refine entities into sub-entities if there are fields
that are relevant for some members and not others. For example a vehicle entity
could have car and lorry sub-entities. One way of doing this is top-down
conceptual refinement, which is a fancy way of saying, start with an entity,
identify it's subclasses, create sub-entities for them, and then repeat for the
newly created sub-entities.

\marginpar{I've not got time to work out how to do $\cup$ arrowheads now, please
draw them on the diagram!}

\begin{center}
  \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
    \node[entity] (emp) {Vehicle};
    \node[attribute] [below=1cm of emp] (rel) {d} edge (emp);
    \node[entity] [below left=1cm of rel] (dep) {Lorry} edge (rel);
    \node[entity] [below right=1cm of rel] (dep2) {Car} edge (rel);
  \end{tikzpicture}
\end{center}

An alternate way to specialise is to do a bottom-up approach. Start with lots of
sets, and define a common superset of them. Here, you're generalising rather
than specialising.

Each subentity can have it's own attributes and relationships of course:

\begin{center}
  \begin{tikzpicture}[node distance=2.5cm, every edge/.style={link}]
    \node[entity] (emp) {Vehicle};
    \node[attribute] [above left=1cm of emp] {Colour} edge (emp);
    \node[attribute] [above right=1cm of emp] {Model} edge (emp);
    \node[attribute] [below=1cm of emp] (rel) {d} edge (emp);
    \node[entity] [below left=1cm of rel] (dep) {Lorry} edge (rel);
    \node[entity] [below right=1cm of rel] (dep2) {Car} edge (rel);
    \node[attribute] [below right=1cm of dep2] {\# Doors} edge (dep2);
    \node[attribute] [below left=1cm of dep2] {\# Seats} edge (dep2);
    \node[relationship] [below =1cm of dep] (rel2) {Registered to} edge (dep);
    \node[entity] [below right=1cm of rel2] {Country} edge (rel2);
  \end{tikzpicture}
\end{center}

Entity subtypes can be user, attribute or predicate defined based on whether the
user has defined them to be a subtype, their attributes define them to be
subtypes or if a predicate has (e.g. if country in EU $\implies$ EU Member).

In the examples, the attribute `d' is used to create a subtype. This stands for
disjoint, since a car can't also be a lorry. There is also `o', which is used
when an entity could belong to multiple subtypes.

\section{Converting an ER diagram into a relational language}

I refer you to Alvaro's sixth lecture, for this part, since it'd take too long
to draw all the diagrams you need. If you're reading this and feeling helpful,
you write this section and send me a pull request!

\section{Normalization}

Normalizeation is the process of decomposing unsatisfactory (i.e. potentially
improvable) relations by creating smaller relations from them. The keys and
functional dependencies of the relation determine it's normal form.

\marginpar{3NF and BCNF (Boyce-Codd Normal Form) are the targets we try and
work towards.}

The normal form indicates a particular quality level of the database schema. 1NF
is a relation in its first normal form, where every field contains only atomic
values. 2NF, 3NF and BCNF are normal forms that are defined in terms of keys and
functional dependencies of a relational schema.

The main technique that we use to try and refine schema is
\textbf{decomposition}. This is the idea of taking a relation ABCD, and
decomposing it into two relations; AB and BCD. Decomposition is guided by the
functional dependencies that hold over the relation.

An example would be a table of Employees. If there was a column for office id
and another for work address, we would have to update all of the employees who
worked at a specific office if the office location moved. If there was a
separate table of offices, we could simply update the office location in that
table, and because of a relation between Employee and Office, we wouldn't have
to update Employee at all!

A key is one or more attributes in a relation where each key is unique for
that relation. There may be more than one valid key (candidate key) for each
entity, if this is the case, then one of them is selected to be the primary
key, and the others are said to be secondary keys.

\subsection{Functional Dependencies}

Functional dependencies are a different way of solving the employee-office
problem mentioned a few paragraphs ago. A functional dependency is basically a
constraint between two attributes in the entity, the notation would be
Office\_ID $\rightarrow$ Office\_Location, if we were to create an FD between
the office ID and it's location.

If an FD is in place, the determinant (the bit before the arrow) determines the
bit after the arrow. Determinants of the same value will \textit{always} map
onto the same value.

The trouble with functional dependencies is what happens when you want to
update the derived value, or insert a new data item that doesn't have a
determinant.

\section{`Advanced SQL'}

When it was conceived, SQL was not Turing complete. In order to get encapsulate
more logic, programmers would use database API's, or embed SQL commands into
another programming language that was Turing complete, where a compiler will
resolve them into code in the host language. This was called
\textit{Programmatic SQL}, but it was hard to do well, since SQL is a
declarative language, and most host languages wouldn't be (they'd be imperative,
object oriented or even functional), so the programming styles (and other, more
fundamental stuff like type systems) would clash.

Another solution is to extend SQL to make it Turing complete. Oracle did this to
create Procedural Language/SQL, which is what we have the privilege of using on
the course.

\subsection{Procedural Language/SQL}

\subsubsection{Anonymous Block}

This is an unnamed block of PL/SQL. This one will print out the number of
students in the student table, and log any errors if it can't.

\begin{verbatim}
  DECLARE
    amount NUMBER := 0;
    error_code NUMBER;
    error_message VARCHAR2(255);

  BEGIN
    SELECT COUNT(*) INTO amount
    FROM STUDENT;

    DBMS_OUTPUT.PUT_LINE(amount);

  EXCEPTION
    error_code := SQLCODE
    error_message = SQLERRM
    INSERT INTO errors VALUES(error_code, error_message);

  END;
\end{verbatim}

\subsubsection{Cursors}

If we run an SQL command that could return an arbitrary number of rows, we need
to use a cursor. This allows us to access one row at a time and iterate over
them.\marginpar{Anybody familiar with Android development will probably have
come across cursors.} It must be declared and opened before use, and closed
after it is finished with. Cursors can be used to update content in tables as
well as just viewing them.

\begin{verbatim}
  CURSOR getStudentsDoingCourse(myCourseName Student.courseName%TYPE) IS
    SELECT *
    FROM Students
    WHERE Students.courseName = myCourseName
    ORDER BY Student.id;
\end{verbatim}

\subsubsection{Subprograms; Procedures and Functions}

Subprograms are named blocks that can be called with parameters. They aid in
abstraction and increase the reusability and maintainability of the code.

Functions always return a single value, whereas procedures don't return any
value. In order to return a value, functions use the \texttt{RETURN} keyword.

Here is an example procedure:

\begin{verbatim}
  CREATE OR REPLACE PROCEDURE getAverageGrade(sID IN Students.ID%TYPE) AS
    var_name Students.name%TYPE;
    var_grade NUMBER;
    var_count NUMBER;
    var_temp NUMBER;

    CURSOR getStudentGrades(sId StudentGrades.ID%TYPE) IS
      SELECT *
      FROM StudentGrades
      WHERE StudentGrades.ID = sID;

    CURSOR getStudentName(sId Students.ID%TYPE) IS
      SELECT name
      FROM Students
      WHERE Students.ID = sID;

    var_error_code NUMBER;
    var_error_message VARCHAR(255);

    BEGIN

      OPEN getStudentGrades(sID);

      LOOP
        FETCH getStudentGrades INTO var_temp;
        EXIT WHEN getStudentGrades%NOTFOUND;

        var_grade := var_grade + var_temp;
        var_count := var_count + 1;
      END LOOP;

      IF getStudentGrades%ISOPEN
        THEN CLOSE getStudentGrades;
      END IF;

      var_grade := var_grade / var_count;
      
      OPEN getStudentName(sID);
      FETCH getStudentName INTO var_name;

      DBMS_OUTPUT.PUT_LINE(var_name || ': ' || var_grade || '%');

      IF getStudentName%ISOPEN
        THEN CLOSE getStudentName;
      END IF;

    EXCEPTION
      WHEN OTHERS
      THEN
        var_error_code := SQLCODE;
        var_error_message := SUBSTR(SQLERRM, 1, 255);
        DBMS_OUTPUT.PUT_LINE(var_error_code || ': ' || var_error_message);

        IF getStudentName%ISOPEN
          THEN CLOSE getStudentName;
        END IF;

        IF getStudentGrades%ISOPEN
          THEN CLOSE getStudentGrades;
        END IF;
    END;
\end{verbatim}

To execute a procedure, do \texttt{EXECUTE getAverageGrade(8955942)}. 

\subsubsection{Triggers}

Triggers are constructs that react to certain conditions. They obey an \textbf
{event-condition-action (ECA)} model.

Triggers can be fired by insertions, deletions or updating rows in a table when
tables are created, altered or dropped, as well as when error messages are
generated. Triggers can fire before, after or instead of the triggering event,
and the \texttt{action} is a block that is executed if the trigger fires.

Row level triggers execute the action that for each row that has changed in a
table, while statement level triggers only execute once per fire event.
Triggers can be made to cascade, if the effects of one cause another to fire. It
is possible that this could result in non-termination.

\begin{verbatim}
  CREATE TRIGGER name
    (BEFORE | AFTER | INSTEAD OF)
    (INSERT | DELETE | UPDATE [OF columns])
  ON tableName
    // (refer to the old/new values of an update)
    [REFERENCING (OLD | NEW) AS (oldName | newName)]
    // Row-level or Statement-level?
    [FOR EACH (ROW | STATEMENT)]
    [WHEN condition]
    triggerAction (e.g. call procedure)
  ;
\end{verbatim}

\section{Transactions, concurrency and recovery}

These are all very important features of a DBMS system, and are some of the
greatest advantages of using a DBMS instead of rolling your own system as a
programmer.

\subsection{Transactions}

A transaction is a action or series of actions carried out by an application on
the database. It can be seen as a logical unit of work on the database, and one
level of abstraction sees client applications as just a series of transactions
with intervals of non-database work in between.

Each transaction moves the database from one state to another (or possible the
same state). Each state is consistent, however, in between states, the database
may be inconsistent (i.e. while processing occurs on the database, constraints
may be violated).

Transactions can have two outcomes, success and failure. If the transaction is
successful, then it will be committed, and the database will enter a new state.
If the transaction fails, then it will be aborted and the database is rolled
back to the state it was in before the start of the transaction. Once a
transaction is committed, it cannot be aborted, but an aborted transaction can
always be restarted later for another attempt.

Transactions have four basic properties, called ACID:

\begin{description}
  \item \textbf{Atomicity}\\
    A transaction is either fully successful, or it's failed; there's no
    in between. This is sometimes called an `all or nothing' contract.
  \item \textbf{Consistency}\\
    The transaction must transform the database from one consistent state to
    another.
  \item \textbf{Isolation}\\
    Partial effects of incomplete transactions are not visible to other
    transactions. All transactions are in effect, sandboxed.
  \item \textbf{Durability}\\
    The effects of a committed transaction are permanent. If a later transaction
    fails, then it will not affect previous transactions.
\end{description}

\subsection{Concurrency}

Concurrency control is important since it allows multiple operations on the
database to take place simultaneously without interfering with each other.

Without concurrency control, if two transactions were to execute in parallel,
they could affect each other and produce incorrect results. Problems can include:

\begin{description}
  \item \textbf{Lost update problem}\\
    If two users update the database at once, the one that finishes first will
    be overridden by the one that finished second. This is mitigated by stopping
    concurrent operations from reading objects/tables while another operation is
    writing to it.
  \item \textbf{Uncommitted dependency problem}\\
    If one operation reads a piece of data while another operation writes to it,
    then the first could read data that is in an intermediate state which is 
    inconsistent. To prevent this from occurring, then we must stop reads from
    occurring on objects that haven't been committed.
  \item \textbf{Inconsistent analysis problem}\\
    If one transaction reads several values, but they are updated by another
    transaction part way through the read, then some of them will be
    inconsistent with the others. To avoid this, again stop one transaction from
    reading while another is updating and vice versa.
\end{description}

\subsubsection{Serializability}

We want to be able to schedule transactions so that they don't interfere with
each other. The easy way of doing this, is to have no concurrency, but this would
severely limit performance. Serializability guarantees sequences of execution
that will ensure consistency.

Lets define some terminology; a \textit{schedule} is a set of of reads and
writes to the database by concurrent transactions, a \textit{serial schedule} is
when the reads and writes must be executed consecutively with no interleaved
operations, and a \textit{non-serial schedule} is one where any operations can
be interleaved.

To make the database as efficient as possible, we want to find as many non-
serial schedules as we can so that we can get parallel computation. These are
called serializable schedules.

The exact order of the reads and writes in the database is important; the
transactions need to execute in a serial manner if one transaction is writing
while another is reading or writing to the same data item. We can use precedence
graphs to test for these conflicts.

In order to create a \textbf{precedence graph}, you create a node for each
transaction and then create a directed edge from $T_i$ to $T_j$ if:

\begin{itemize}
  \item $T_j$ reads the value of an item written by $T_i$
  \item $T_j$ writes a value into an item after it has been read by $T_i$
  \item $T_j$ writes a value into an item after it has been written by $T_i$.
\end{itemize}

When you've drawn a precedence graph, you must run a cycle finding algorithm on
it (such as Floyd's cycle finding algorithm). If a cycle is present, then the
transactions must run in a serial manner.

\subsubsection{Concurrency control techniques}

The two most basic control techniques are locking and timestamping. Both
techniques are pessimistic, which means that they delay a transaction in case it
conflicts with another transaction.

Locking is when data items are locked to prevent other transactions from viewing
or updating them (depending on the type of lock obtained). Transactions must
obtain a shared lock on a data item when it wants to read, and an exclusive lock
when it wants to write.

In order to ensure that assigning locks doesn't violate isolation and atomicity
rules for the database, locks are assigned (usually) using the two-phase-locking
(2PL) protocol.

The \textbf{Two Phase Locking} protocol, as you might expect, has two phases;
the growing phase and the shrinking phase. In the growing phase, the transaction
may acquire locks but cannot release them, and in the shrinking phase, it can
release locks but cannot acquire them. If all transactions follow 2PL, then the
schedule is serializable.

If transactions depend on each other (due to locks being released before a
transaction ends), then \textbf{cascading rollback} can occur. If T3 depends on
T2, which depends on T1 and T1 is rolled back, then both T3 and T2 must also be
rolled back. This can be stopped by ensuring that locks are only released at
the end of transactions (since they have then been committed), which is called
rigorous 2PL.

Deadlock can occur if two transactions are waiting from a lock from each other.
If this happens, then one or more of the transactions should be aborted and
restarted. Deadlock can be detected using timeouts (only waiting $n$ seconds to
acquire a lock).

\subsubsection*{Recovery}

You can keep a transaction log of all actions executed on a database. This log
is stored in a file on (often) a backup system. If the database becomes
corrupted, you can simply replay the transactions in the log and get the
database back to the state it was in.

Shadow paging is another recovery technique, where a copy of the page a
transaction is taking place on is created. If the transaction fails, you can
simply replace the page with the copy and it will be the same as before.
