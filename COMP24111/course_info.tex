\section*{Introduction}

Machine learning is concerned with creating mathematical "data structures" that
allow a computer to exhibit behaviour that would normally require a human.
Typical applications might be spam filtering, speech recognition, medical
diagnosis, or weather prediction. The data structures we use (known as "models")
come in various forms, e.g. trees, graphs, algebraic equations, probability
distributions. The emphasis is on constructing these models automatically from
data---for example making a weather predictor from a datafile of historical
weather patterns. This course will introduce you to the concepts behind various
Machine Learning techniques, including how they work, and use existing software
packages to illustrate how they are used on data. The course has a fairly
mathematical content although it is intended to be self-contained.

\section*{Aims}

To introduce methods for extracting rules or learning from data, and provide the
necessary mathematical background to enable students to understand how the
methods work and how to get the best performance from them. This course covers
basics of both supervised and unsupervised learning paradigms and is pitched
towards any student with a mathematical or scientific background who is
interested in adaptive techniques for learning from data as well as data
analysis and modelling.

\section*{Contributing \& Attribution}

These notes are open-sourced on Github at
\url{https://github.com/Todd-Davies/second-year-notes}. Please feel free to
submit a pull request if you want to make any changes, or maybe open an issue
if you find an error! Feedback is very welcome; you can email me at
\href{mailto:todd434@gmail.com}{todd434@gmail.com}.

These notes are based on the \texttt{COMP24111} lecture notes by Dr. Gavin Brown
and Dr. Ke Chen.

\section*{Additional reading}

\begin{tabularx}{\textwidth}{X|X|l}
   Introduction to machine learning (2nd edition) & Alpaydin, Ethem & 2010\\
\end{tabularx}